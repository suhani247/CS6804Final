{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = pd.read_csv('../data/attack_annotated_comments.tsv', sep = '\\t', index_col = 0)\n",
    "annotations = pd.read_csv('../data/attack_annotations.tsv',  sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# labels a comment as an atack if the majority of annoatators did so\n",
    "labels = annotations.groupby('rev_id')['attack'].mean() > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join labels and comments\n",
    "comments['attack'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "# remove newline and tab tokens\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"NEWLINE_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.replace(\"TAB_TOKEN\", \" \"))\n",
    "comments['comment'] = comments['comment'].apply(lambda x: x.lower())\n",
    "comments['comment'] = comments['comment'].apply(lambda x: \"\".join(l for l in x if l not in string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swear_words = \"../swear_words.txt\"\n",
    "word_list = []\n",
    "with open(swear_words) as f:\n",
    "    word_list = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def tokens(post):\n",
    "    return TextBlob(post.decode('utf8')).words\n",
    "    \n",
    "def get_bad_word_count(post):\n",
    "    x = tokens(post)\n",
    "    count = 0\n",
    "    bad_words = []\n",
    "    for word in x:\n",
    "        if word in word_list:\n",
    "            count+=1\n",
    "            bad_words.append(word)\n",
    "    return count, str(bad_words)\n",
    "\n",
    "comments['bad_word_count'],comments['bad_word_list']= zip(*comments['comment'].map(get_bad_word_count)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_analysis(comments):\n",
    "    total = len(comments)\n",
    "    bully = len(comments[comments['attack']==1])\n",
    "    swear = len(comments[comments['bad_word_count']>0])\n",
    "    anonymous = len(comments[comments['logged_in']==0])\n",
    "    swear_bully = len(comments[(comments['bad_word_count']>0) & (comments['attack']==1) ])\n",
    "    anonymous_bully = len(comments[(comments['attack']==1) & (comments['logged_in']==0)])\n",
    "    anonymous_swear = len(comments[(comments['bad_word_count']>0)  & (comments['logged_in']==0)])\n",
    "    anonymous_bully_swear = len(comments[(comments['attack']==1) & (comments['bad_word_count']>0)  & (comments['logged_in']==0)])\n",
    "    \n",
    "    P_B = float(bully)/total\n",
    "    P_S = float(swear)/total\n",
    "    P_A = float(anonymous)/total\n",
    "    P_B_S = float(swear_bully)/swear\n",
    "    P_S_B = float(swear_bully)/bully\n",
    "    P_B_A = float(anonymous_bully)/anonymous\n",
    "    P_A_B = float(anonymous_bully)/bully\n",
    "    P_S_A = float(anonymous_swear)/anonymous\n",
    "    P_A_S = float(anonymous_swear)/total\n",
    "    P_B_A_S = float(anonymous_bully_swear)/ anonymous_swear\n",
    "    \n",
    "    print(\"P(B): \" + str(P_B))\n",
    "    print(\"P(S): \" + str(P_S))\n",
    "    print(\"P(A): \" + str(P_A))\n",
    "    print(\"P(B|S): \" + str(P_B_S))\n",
    "    print(\"P(S|B): \" + str(P_S_B))\n",
    "    print(\"P(B|A): \" + str(P_B_A))\n",
    "    print(\"P(A|B): \" + str(P_A_B))\n",
    "    print(\"P(S|A): \" + str(P_S_A))\n",
    "    print(\"P(B|A & S): \" + str(P_B_A_S))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
